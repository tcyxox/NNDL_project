@INPROCEEDINGS {7780542,
author = { Bendale, Abhijit and Boult, Terrance E. },
booktitle = { 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) },
title = {{ Towards Open Set Deep Networks }},
year = {2016},
volume = {},
ISSN = {1063-6919},
pages = {1563-1572},
abstract = { Deep networks have produced significant gains for various visual recognition problems, leading to high impact academic and commercial applications. Recent work in deep networks highlighted that it is easy to generate images that humans would never classify as a particular object class, yet networks classify such images high confidence as that given class â€“ deep network are easily fooled with images humans do not consider meaningful. The closed set nature of deep networks forces them to choose from one of the known classes leading to such artifacts. Recognition in the real world is open set, i.e. the recognition system should reject unknown/unseen classes at test time. We present a methodology to adapt deep networks for open set recognition, by introducing a new model layer, OpenMax, which estimates the probability of an input being from an unknown class. A key element of estimating the unknown probability is adapting Meta-Recognition concepts to the activation patterns in the penultimate layer of the network. Open-Max allows rejection of "fooling" and unrelated open set images presented to the system, OpenMax greatly reduces the number of obvious errors made by a deep network. We prove that the OpenMax concept provides bounded open space risk, thereby formally providing an open set recognition solution. We evaluate the resulting open set deep networks using pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation data, and thousands of fooling and open set images. The proposed OpenMax model significantly outperforms open set recognition accuracy of basic deep networks as well as deep networks with thresholding of SoftMax probabilities. },
keywords = {Visualization;Sports equipment;Training;Adaptation models;Computational modeling;Whales;Extraterrestrial measurements},
doi = {10.1109/CVPR.2016.173},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.173},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Jun}

@misc{guth2025learningnormalizedimagedensities,
      title={Learning normalized image densities via dual score matching},
      author={Florentin Guth and Zahra Kadkhodaie and Eero P Simoncelli},
      year={2025},
      eprint={2506.05310},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.05310},
}

@misc{hendrycks2018baselinedetectingmisclassifiedoutofdistribution,
      title={A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks},
      author={Dan Hendrycks and Kevin Gimpel},
      year={2018},
      eprint={1610.02136},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1610.02136},
}

@inproceedings{mahdavi2021survey,
  title={A survey on open set recognition},
  author={Mahdavi, Atefeh and Carvalho, Marco},
  booktitle={2021 IEEE Fourth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)},
  pages={37--44},
  year={2021},
  organization={IEEE}
}

@article{sun2023survey,
  title={A survey on open-set image recognition},
  author={Sun, Jiayin and Dong, Qiulei},
  journal={arXiv preprint arXiv:2312.15571},
  year={2023}
}

@article{geng2020recent,
  title={Recent advances in open set recognition: A survey},
  author={Geng, Chuanxing and Huang, Sheng-jun and Chen, Songcan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={10},
  pages={3614--3631},
  year={2020},
  publisher={IEEE}
}

@inproceedings{miller2021class,
  title={Class anchor clustering: A loss for distance-based open set recognition},
  author={Miller, Dimity and Sunderhauf, Niko and Milford, Michael and Dayoub, Feras},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3570--3578},
  year={2021}
}